version: "3.9"

services:
  pyspark_ml:
    build: 
      context: .
      dockerfile: Dockerfile.pyspark
    image: pyspark_ml_image 
    container_name: pyspark_ml_fraud
    
    volumes:
      - ./spark_streaming_processor.py:/home/jovyan/work/spark_streaming_processor.py 
      - ./requirements.txt:/home/jovyan/work/requirements.txt
      - ./model:/home/jovyan/work/model 

    networks:
      - fraud_detection_network
    
    # รอ Kafka และ Postgres พร้อม (ไม่ต้องใช้ depends_on เพราะคนละ compose)
    command: /usr/local/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 --driver-class-path /usr/local/spark/jars/postgresql-42.5.0.jar /home/jovyan/work/spark_streaming_processor.py

networks:
  fraud_detection_network:
    external: true